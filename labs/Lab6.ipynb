{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Microbial Genomics: Lab 6\n",
    "## Topic: Burrows-Wheeler Alignments and SNP Calling\n",
    "#### Tools used: BWA, SAMTools, VCFTools, fastq-dump, Snippy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part A: Lab Exercises\n",
    "### Exercise 1: Implementing a simple Burrows-Wheeler Transform\n",
    "As we discussed in class, the Burrows-Wheeler algorithm is an important concept in bioinformatics because it gives us a way to distinctly represent, align and search very large strings in an efficient way. To start this lab, we'll look a little more closely at Burrows-Wheeler Transforms (BWT).\n",
    "\n",
    "First off, you might still be wondering about why BWT is actually important. After all, the main problem that the BWT is used to solve in bioinformatics is searching for one block of text within a larger block. At the most basic level, we learned a few Bash commands that can search text- think of `grep`. Since sequence data is just text, can't we just use these tools to perform such searches? In theory, yes- but as with so many things in the world of bioinformatics, the problem is a balance between memory and time.\n",
    "\n",
    "Consider the file `sample_reads.fastq` in the lab6 folder. This file has about 75,000 sequences, or about 11,000,000 reads. Say we want to search for the sequence `GATTTCCTCCTGACCAGTCG` in this file; we could do this by executing the command below. \n",
    "\n",
    "*Note: we use the `time` function to get the timing statistics of the function call, and we direct the command output to `/dev/null/` as a convention to avoid a lot of noisy output in this notebook.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "time cat lab6/sample_reads.fastq | grep \"GATTTCCTCCTGACCAGTCG\" > /dev/null"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So- searching a 20-length sequence across 11M reads took about 0.5 seconds. That might not seem bad; however, when you consider that this is in fact an rather small fastq file (it's not uncommon to have bacterial sequences on the order of 100x larger), that 0.5 seconds now becomes 50 seconds. That doesn't seem so bad either, but we typically aren't just querying sequences from one organism- we are querying databases with hundreds of millions of sequences. This adds up quickly- and this is a single, relatively simple query. If we begin thinking about alignment and queries involving multiple sequences, it should be clear that in order to perform bioinformatics at scale, we need a faster solution. Indexing could speed up our search problem- but at the expense of requiring *a lot* of storage space. A single human genome would require ~200GB to index; think about trying to do this for every possible species!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So, now that we've discussed why BWT is relevant, let's talk about what it means. We discussed and practiced performing a BWT manually, but how would you do so programmatically? Let's break it down into steps, and consider the word `DOGS$` for simplicity. First, we need to generate our matrix of \"rotations\"; i.e., `$DOGS`, `S$DOG`, `GS$DO`, and `OGS$D`. These form our Burrows-Wheeler Matrix:\n",
    "\n",
    "```\n",
    "DOGS$\n",
    "OGS$D\n",
    "GS$DO\n",
    "S$DOG\n",
    "$DOGS\n",
    "```\n",
    "\n",
    "From a python standpoint, we could loop N times and generate these using something like the following pseudocode:\n",
    "\n",
    "```\n",
    "def rotations(word):\n",
    "\n",
    "    rotation_list = []\n",
    "    for all i from 0 to length of word:\n",
    "    \n",
    "        rotation_list[i] = word[i to end] + word[0 to i-1]\n",
    "        \n",
    "    return rotation_list\n",
    "```\n",
    "    \n",
    "This code would return a list of all rotations of the input word. (How would you do this using a list comprehension?)\n",
    "\n",
    "Now, we need to sort our list, so that it ends up in a form like:\n",
    "\n",
    "```\n",
    "$DOGS\n",
    "DOGS$\n",
    "GS$DO\n",
    "OGS$D\n",
    "S$DOG\n",
    "```\n",
    "\n",
    "This is equivalent to sorting the output of our `rotations` function above. Once we have this sorted BWM, we can get the BWT by taking the last letter of each row (i.e., the last letter of each element in the sorted list in Python).\n",
    "\n",
    "Use the cell below to implement a function that takes in any arbitrary word, and returns its BWT. You can implement the internals any way you'd like, as long as the valid transformation is returned. Demonstrate that your function works on a word of your choosing after you define it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exercise 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 2: Using the `bwa` package\n",
    "Above, we implemented a very simple Burrows Wheeler Transform. In reality, our Computer Science friends have been hard at work over the past 40 years making much, much more sophisticated versions of this code; there are doctoral dissertations on this topic alone. Fortunately for us, we get to reap the benefits of this hard work without getting a PhD!\n",
    "\n",
    "There are quite a few packages that use BWT (or a related variant), but we'll focus on the `bwa`, or Burrows-Wheeler Alignment, package. You can see the basics of the tool, as always, by typing `bwa` in the command line (or the below cell):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%%bash\n",
    "bwa"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You should note from this output that `bwa` has quite a few subcommands; the output also gives a brief description of each. The main ones of note for us are `index`, `mem`, `aln`, and `sampe`. **Do your own investigation into each of these and answer the questions below:**\n",
    "\n",
    "1. What does each of the 4 subcommands listed above do?\n",
    "2. If you were given a .fasta reference file and two paired end .fastq files as inputs, and wanted to output a .sam file, what command(s) would you run?\n",
    "3. Read the documentation at https://github.com/lh3/bwa. Is there more than one way to answer the above question? If so, what is the alternative to the answer you gave? Is there any reason to use one over another?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exercise 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 3: Variants\n",
    "Above, we learned about creating alignments with BWA; we've performed a similar workflow with Samtools in Lab 4. BWA-MEM is a much easier and faster way to perform alignments, and more importantly, brings us to our next topic: what do we do with those SAM files we generated?\n",
    "\n",
    "One common question bioinformaticians usually want to answer when dealing with a sequence is, \"how is this sequence different from a known reference\"? Alignment of two sequences gives us a \"birds-eye\" view of the differences between them, but we can look for more granular differences in the form of single nucleotide polymorphisms (SNPs), also known as \"variants\". These are common mutations where a single nucleotide has changed, and can be quantified. The act of finding these variants between two genomes is known as \"SNP Calling\" or \"Variant Calling\".\n",
    "\n",
    "To perform SNP calling, we need two things: a reference, or known, genome, and a \"new\" genome that we want to compare it to. Different tools have different requirements on the formats of these inputs, but there are 4 main input filetypes you will encounter:\n",
    "* `.fasta`, for the reference genome: this is our well-known friend- nothing new about it.\n",
    "* `.gbk`, for the reference genome: a genbank file is sometimes used as the reference input; this can be retrived from any sequence on NCBI.\n",
    "* `.fastq`, for the genome to be called: some tools will accept raw fastq reads; this is the easiest option.\n",
    "* `.BAM`, for genome to be called: this is a binary-compressed version of the `.SAM` format, which contains aligned, mapped sequences.\n",
    "\n",
    "The output files will generally be one of two filetypes:\n",
    "* VCF files are uncompressed files that contain variants found in a sequence compared to a reference. \n",
    "* BCF files are a binary compressed version of VCF files.\n",
    "\n",
    "A VCF file will look something like this:\n",
    "```\n",
    "##fileformat=VCFv4.3\n",
    "##fileDate=20090805\n",
    "##source=myImputationProgramV3.1\n",
    "##reference=file:///seq/references/1000GenomesPilot-NCBI36.fasta\n",
    "< ... more lines go here ... >\n",
    "#CHROM POS      ID         REF   ALT    QUAL  FILTER   INFO                             FORMAT       NA00001         NA00002          NA00003\n",
    "20     14370    rs6054257  G     A      29    PASS    NS=3;DP=14;AF=0.5;DB;H2           GT:GQ:DP:HQ  0|0:48:1:51,51  1|0:48:8:51,51   1/1:43:5:.,.\n",
    "20     17330    .          T     A      3     q10     NS=3;DP=11;AF=0.017               GT:GQ:DP:HQ  0|0:49:3:58,50  0|1:3:5:65,3     0/0:41:3\n",
    "20     1110696  rs6040355  A     G,T    67    PASS    NS=2;DP=10;AF=0.333,0.667;AA=T;DB GT:GQ:DP:HQ  1|2:21:6:23,27  2|1:2:0:18,2     2/2:35:4\n",
    "20     1230237  .          T     .      47    PASS    NS=3;DP=13;AA=T                   GT:GQ:DP:HQ  0|0:54:7:56,60  0|0:48:4:51,51   0/0:61:2\n",
    "20     1234567  microsat1  GTC   G,GTCT 50    PASS    NS=3;DP=9;AA=G                    GT:GQ:DP     0/1:35:4        0/2:17:2         1/1:40:3\n",
    "```\n",
    "\n",
    "Here, we have a bunch of reference information preceded with `##` at the top, followed by tab-separated variant information. Each line in the \"main\" table of the file represents one variant.\n",
    "\n",
    "To try out some variant calling, we'll first use BWA to generate our aligned `.sam` files, convert to `.bam` with SAMTools, and then call variants using BCFTools, which is a sub-tool of SAMTools. The pipeline will look like this:\n",
    "1. Index the reference file R64_ref.fasta located in lab4/reference using bwa index\n",
    "2. Input paired-end fastq and reference fasta files to `bwa-mem`; output a SAM file\n",
    "3. Input the SAM file to `samtools view -bS` and output a BAM file\n",
    "4. Sort the BAM file using `samtools sort` to output a sorted BAM file\n",
    "5. Generate a BCF by using the `samtools mpileup` and `bcftools call` commands. For bcftools view, use `view -Obvcg` instead of `view -bvcg` as in the example tutorial. This specifies the output file type.\n",
    "\n",
    "**Based on this information, complete the below exercises:**\n",
    "1. Familiarize yourself with the SAMTools SNP-calling pipeline by reading [this guide](http://quinlanlab.org/tutorials/samtools/samtools.html) and [this guide](http://samtools.sourceforge.net/mpileup.shtml) and performing your own research on Google, Biostars, etc. Once you feel confident that you understand the steps, write a pipeline that uses r1.trimmed.fastq, r2.trimmed.fastq, and R64_ref.fasta from the lab4 folder to generate a BCF file of variants between the fastq files and the reference fasta.\n",
    "2. Investigate the BCF file you just generated by using the `bcftools view` command to convert your BCF file to a VCF file. Open this file in your text editor of choice. How many variants did you find?\n",
    "3. Do some basic analytics of your VCF file. You can do this either by using Excel (copy all of the lines after `##` ends), or using Python, MATLAB, or your programming tool of choice. What are the most common variants you called (hint: these are the values in the `ALT` column)? \n",
    "4. Does the VCF tell us what each of these mutations actually does? If not, what other information would we need to make some judgement about the impact of each variant?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "#bwa index lab4/reference/R64_ref.fasta\n",
    "#bwa mem lab4/reference/R64_ref.fasta lab4/trimmed_fastq/r1.trimmed.fastq.gz lab4/trimmed_fastq/r2.trimmed.fastq.gz > lab6/R64_aln-pe.sam\n",
    "#samtools view -S -b lab6/R64_aln-pe.sam > lab6/R64_aln-pe.bam\n",
    "#samtools sort lab6/R64_aln-pe.bam -o lab6/R64_sorted.bam\n",
    "samtools mpileup -uf lab4/reference/R64_ref.fasta lab6/R64_sorted.bam | bcftools view -Obvcg - > lab6/R64.bcf  \n",
    "bcftools view lab6/R64.bcf  | vcfutils.pl varFilter -D100 > lab6/var.flt.vcf  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 4: SNP Calling with Snippy\n",
    "SAMTools is part of the \"classic\" variant-calling pipeline; it was one of the very early tools developed to aid bioinformaticians in understanding their data. However, as you likely saw in the previous exercise, it is not always the most user-friendly tool. Another tool we can use to build a variant-calling pipeline is `snippy`, from the (rather prolific) Australian Bioinformatician Torsten Seemann. The github page can be found [here](https://github.com/tseemann/snippy); take some time to read through it. It is already installed in this environment, so you can view the help as usual:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "snippy -h"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Snippy is a very useful tool for several reasons:\n",
    "* It can take as inputs our fastq files directly; there's no need to align them first\n",
    "* It can take a Genbank file as an input, which can be directly downloaded from NCBI (i.e., using Biopython)\n",
    "* It outputs a host of very useful files, most of which are very user-friendly (unlike raw VCFs)\n",
    "\n",
    "Complete the exercise below using `snippy`:\n",
    "1. Run `snippy` on the same reads as above (r1.trimmed.fastq.gz and r2.trimmed.fastq.gz in the lab4/trimmed_fastq folder; output should be placed in lab6/results/)\n",
    "2. Look through the output generated by `snippy`; open the .html file that was generated. Summarize and discuss your findings. What is the main difference between the Snippy output and VCFtools output? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "# Exercise 4\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part B: Homework"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We've talked about several different technologies in this lab; now, we'll put a few of them to use. Your homework this week will be to explore mutations in a resistant strain of *E. Coli* isolated from patients in a CDC study. It will be your job to write code that accomplishes the following:\n",
    "\n",
    "0. Download the samples from NCBI's SRA (short read) database (this is done for you)\n",
    "1. QC and trim the input fastq files as you deem necessary\n",
    "2. Download the reference genome for that strain using Entrez and the accession ID: NZ_CP015085.1\n",
    "3. Align your fastq reads to the reference, and call variants using whichever tool you prefer.\n",
    "4. Analyze and summarize your findings in a comment at the end of the pipeline, including any literature you feel may be relevant, along with your thoughts on what additional information you need to make the data you found more informative.\n",
    "\n",
    "You can write each step in a separate script, use this notebook, or write several external scripts, but you must provide a write-up of your findings in the cell below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23a8ec9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# First of all, we need to make sure our SRA toolkit is at least version 3,\n",
    "# or else it will refuse to download the data.\n",
    "\n",
    "! conda install -y -c bioconda sra-tools==3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# download our fastq samples from NCBI SRA\n",
    "# this may take several minutes\n",
    "!fastq-dump --split-3 -O lab6/samples SRR11594676"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Homework Code and Writeup Goes Here"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
